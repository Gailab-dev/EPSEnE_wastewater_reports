# REQ002 ìœ ì…ìˆ˜ ë¶€í•˜ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ ë¦¬ë·°

**ì‘ì„±ì¼**: 2025-11-20

---

## ğŸ“‹ ëª¨ë¸ ê°œìš”

- **ëª¨ë¸ ID**: REQ002
- **ëª©ì **: ìœ ì…ìˆ˜ BOD, TN, TP ë¶€í•˜ëŸ‰ ë™ì‹œ ì˜ˆì¸¡
- **ì•Œê³ ë¦¬ì¦˜**: XGBoost Multi-Output Regression
- **ë°ì´í„°ì…‹**: `dataset/20251024/ìœ ì…ìˆ˜.csv` (8,756 records, 2024ë…„ ì‹œê°„ë‹¹ ë°ì´í„°)
- **ì…ë ¥ ë³€ìˆ˜**: ìœ ì…ìœ ëŸ‰, ìœ ì…BOD, ìœ ì…TN, ìœ ì…TP, ìœ ì…TOC, ìœ ì…SS
- **ì¶œë ¥ ë³€ìˆ˜**: BOD_ë¶€í•˜ëŸ‰, TN_ë¶€í•˜ëŸ‰, TP_ë¶€í•˜ëŸ‰
- **í”¼ì²˜ ìˆ˜**: 45ê°œ (Lag: 1h, 24h, 168h + Rolling statistics 24h)

---

## ğŸ”´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì‚¬í•­

### 1. **ê³¼ì í•© (Overfitting) ì§•í›„**
- **í˜„ìƒ**: Train RÂ² = 0.9997, Test RÂ² = 0.996~0.997ë¡œ ë§¤ìš° ë†’ìŒ
- **ìœ„í—˜ì„±**: ì‹¤ì œ ìš´ì˜ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ í¬ê²Œ í•˜ë½í•  ê°€ëŠ¥ì„±
- **ì›ì¸**:
  - ê³¼ë„í•œ í”¼ì²˜ ìˆ˜ (45ê°œ)
  - ì •ê·œí™” íŒŒë¼ë¯¸í„° ë¶€ì¡±
  - ë‹¨ì¼ Train/Test Splitìœ¼ë¡œ ì¸í•œ ê²€ì¦ ë¶€ì¡±

### 2. **MAPE ê³„ì‚° ì˜¤ë¥˜**
- **í˜„ìƒ**: TN ë¶€í•˜ëŸ‰ MAPE = inf%
- **ì›ì¸**: 0ì— ê°€ê¹Œìš´ ì‹¤ì œê°’ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°œìƒ
- **ì˜í–¥**: í‰ê°€ ì§€í‘œë¡œ ì‹ ë¢°í•  ìˆ˜ ì—†ìŒ

### 3. **ë°ì´í„° ëˆ„ìˆ˜ (Data Leakage) ìœ„í—˜**
- **í˜„ìƒ**: Lag 1ì‹œê°„ í”¼ì²˜ ì‚¬ìš©
- **ë¬¸ì œì **: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œì (t)ì—ì„œ t-1ì‹œê°„ ë°ì´í„°ê°€ ì•„ì§ ì—†ì„ ìˆ˜ ìˆìŒ
- **ì˜í–¥**: ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥

### 4. **ì‹œê³„ì—´ ê²€ì¦ ì „ëµ ë¶€ì¬**
- **í˜„ìƒ**: ë‹¨ì¼ 80/20 ë¶„í• ë§Œ ìˆ˜í–‰
- **ë¶€ì¡±í•œ ë¶€ë¶„**:
  - Time Series Cross-Validation ì—†ìŒ
  - ê³„ì ˆì„±, íŠ¸ë Œë“œ ë³€í™”ì— ëŒ€í•œ ê²€ì¦ ë¶€ì¡±
  - íŠ¹ì • ê¸°ê°„ì—ë§Œ ìµœì í™”ë  ìœ„í—˜

### 5. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•œê³„**
- **ë¶€ì¡±í•œ í”¼ì²˜**:
  - ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ í”¼ì²˜ (BOD/TN ë¹„ìœ¨, C/N ratio ë“±)
  - ê³„ì ˆì„± í”¼ì²˜ (ì›”, ìš”ì¼, ì‹œê°„ëŒ€)
  - ì™¸ë¶€ ë³€ìˆ˜ (ê°•ìˆ˜ëŸ‰, ì˜¨ë„ ë“±)
- **ì˜í–¥**: ëª¨ë¸ì˜ í•´ì„ë ¥ ë° ì¼ë°˜í™” ì„±ëŠ¥ ì œí•œ

### 6. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë¶€ì¬**
- **í˜„ìƒ**: ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš© (`max_depth=6`, `learning_rate=0.1`)
- **ë¬¸ì œì **: GridSearch, Bayesian Optimization ë“± ì²´ê³„ì  íŠœë‹ ë¯¸ìˆ˜í–‰
- **ì˜í–¥**: ìµœì  ì„±ëŠ¥ ë¯¸ë‹¬ì„±

### 7. **ì´ìƒì¹˜ ì²˜ë¦¬ ì „ëµ ë¶€ì¡±**
- **í˜„ìƒ**: ì›ë³¸ ë°ì´í„°ì˜ ì´ìƒì¹˜ë¥¼ ê·¸ëŒ€ë¡œ í•™ìŠµ
- **ìœ„í—˜ì„±**: ê·¹ë‹¨ê°’ì— ê³¼ë„í•˜ê²Œ í•™ìŠµë  ê°€ëŠ¥ì„±
- **ì˜í–¥**: ì •ìƒ ë²”ìœ„ ì˜ˆì¸¡ ì •í™•ë„ ì €í•˜

### 8. **ì‹¤ì‹œê°„ ìš´ì˜ ê³ ë ¤ì‚¬í•­ ë¶€ì¡±**
- **ë¬¸ì œì **:
  - 168ì‹œê°„(7ì¼) Lag í”¼ì²˜ë¡œ ì¸í•´ ì´ˆê¸° ì˜ˆì¸¡ ë¶ˆê°€ (Cold Start Problem)
  - ê²°ì¸¡ì¹˜ ë°œìƒ ì‹œ ëŒ€ì‘ ì „ëµ ì—†ìŒ
  - ëª¨ë¸ ì¬í•™ìŠµ ì£¼ê¸° ë¯¸ì •ì˜
- **ì˜í–¥**: ì‹¤ì œ ë°°í¬ ì‹œ ìš´ì˜ ë¶ˆê°€ëŠ¥

---

## âœ… ê°œì„ ë°©ì•ˆ ì œì•ˆ

### 1. **ê³¼ì í•© í•´ê²°**

**ë°©ë²•**: ì •ê·œí™” ê°•í™” ë° ì¡°ê¸° ì¢…ë£Œ í™œìš©

```python
# ì •ê·œí™” ê°•í™”
xgb_params = {
    'max_depth': 4,  # 6 â†’ 4ë¡œ ê°ì†Œ
    'learning_rate': 0.05,  # 0.1 â†’ 0.05ë¡œ ê°ì†Œ
    'subsample': 0.8,  # í–‰ ìƒ˜í”Œë§ ì¶”ê°€
    'colsample_bytree': 0.8,  # ì—´ ìƒ˜í”Œë§ ì¶”ê°€
    'reg_alpha': 0.1,  # L1 ì •ê·œí™”
    'reg_lambda': 1.0,  # L2 ì •ê·œí™”
    'n_estimators': 200,
    'random_state': 42
}

# ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬ ë° ì¡°ê¸° ì¢…ë£Œ
from sklearn.model_selection import train_test_split

X_train_full, X_val, y_train_full, y_val = train_test_split(
    X_train, y_train, test_size=0.2, shuffle=False
)

base_model = XGBRegressor(**xgb_params)
model = MultiOutputRegressor(base_model)

# ì¡°ê¸° ì¢…ë£Œ ì ìš© (ê°œë³„ estimatorë§ˆë‹¤)
for i, estimator in enumerate(model.estimators_):
    estimator.fit(
        X_train_full, y_train_full[:, i],
        eval_set=[(X_val, y_val[:, i])],
        early_stopping_rounds=50,
        verbose=False
    )
```

**ê¸°ëŒ€ íš¨ê³¼**: Test RÂ² 0.85~0.90 ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ

---

### 2. **MAPE ê³„ì‚° ìˆ˜ì •**

**ë°©ë²•**: Epsilon ì¶”ê°€ ë˜ëŠ” sMAPE ì‚¬ìš©

```python
# ë°©ë²• 1: Epsilon ì¶”ê°€ë¡œ 0 ë‚˜ëˆ„ê¸° ë°©ì§€
def safe_mape(y_true, y_pred, epsilon=1e-10):
    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100

# ë°©ë²• 2: sMAPE (Symmetric MAPE) ì‚¬ìš©
def smape(y_true, y_pred):
    denominator = (np.abs(y_true) + np.abs(y_pred))
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / denominator)

# ì ìš©
for i, target in enumerate(target_columns):
    mape = safe_mape(y_test[:, i], y_pred[:, i])
    print(f'{target} Test MAPE: {mape:.2f}%')
```

**ê¸°ëŒ€ íš¨ê³¼**: ì•ˆì •ì ì¸ ì˜¤ì°¨ìœ¨ ì¸¡ì • ê°€ëŠ¥

---

### 3. **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**

**ë°©ë²•**: 1ì‹œê°„ Lag ì œê±° ë° ì˜ˆì¸¡ ì‹œì  ëª…í™•í™”

```python
# 1ì‹œê°„ Lag ì œê±° (ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œ ì‚¬ìš© ë¶ˆê°€)
lag_periods = [24, 168]  # 1 ì œê±°

# ì˜ˆì¸¡ ì‹œì  ëª…í™•í™” ì£¼ì„ ì¶”ê°€
# t ì‹œì ì—ì„œ t+1 ì‹œì  ì˜ˆì¸¡ (1ì‹œê°„ í›„ ì˜ˆì¸¡)
# t ì‹œì ê¹Œì§€ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
for feature in lag_features:
    for lag in lag_periods:
        df[f'{feature}_lag{lag}'] = df[feature].shift(lag)
```

**ê¸°ëŒ€ íš¨ê³¼**: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ ë³€ê²½

---

### 4. **Time Series Cross-Validation ë„ì…**

**ë°©ë²•**: TimeSeriesSplitì„ í™œìš©í•œ êµì°¨ ê²€ì¦

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
cv_scores = {'BOD': [], 'TN': [], 'TP': []}

for train_idx, val_idx in tscv.split(X):
    X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]
    y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]

    model.fit(X_train_cv, y_train_cv)
    y_pred_cv = model.predict(X_val_cv)

    for i, target in enumerate(target_columns):
        r2 = r2_score(y_val_cv[:, i], y_pred_cv[:, i])
        cv_scores[target].append(r2)

# êµì°¨ ê²€ì¦ ê²°ê³¼ ì¶œë ¥
for target in target_columns:
    mean_r2 = np.mean(cv_scores[target])
    std_r2 = np.std(cv_scores[target])
    print(f'{target} CV RÂ² Mean: {mean_r2:.4f} Â± {std_r2:.4f}')
```

**ê¸°ëŒ€ íš¨ê³¼**: ê³„ì ˆì„± ë° íŠ¸ë Œë“œ ë³€í™”ì— ëŒ€í•œ ì•ˆì •ì„± ê²€ì¦

---

### 5. **ë„ë©”ì¸ ê¸°ë°˜ í”¼ì²˜ ì¶”ê°€**

**ë°©ë²•**: ê³„ì ˆì„±, ë¹„ìœ¨, ë³€í™”ìœ¨ í”¼ì²˜ ìƒì„±

```python
# ì‹œê°„ í”¼ì²˜
df['ì¸¡ì •ì¼ì‹œ'] = pd.to_datetime(df['ì¸¡ì •ì¼ì‹œ'])
df['month'] = df['ì¸¡ì •ì¼ì‹œ'].dt.month
df['hour'] = df['ì¸¡ì •ì¼ì‹œ'].dt.hour
df['day_of_week'] = df['ì¸¡ì •ì¼ì‹œ'].dt.dayofweek
df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

# ë¹„ìœ¨ í”¼ì²˜ (í•˜ìˆ˜ì²˜ë¦¬ ë„ë©”ì¸ ì§€ì‹)
df['BOD_TN_ratio'] = df['ìœ ì…BOD'] / (df['ìœ ì…TN'] + 1e-10)  # C/N ratio ê·¼ì‚¬
df['BOD_TP_ratio'] = df['ìœ ì…BOD'] / (df['ìœ ì…TP'] + 1e-10)
df['TN_TP_ratio'] = df['ìœ ì…TN'] / (df['ìœ ì…TP'] + 1e-10)
df['COD_BOD_ratio'] = df['ìœ ì…TOC'] / (df['ìœ ì…BOD'] + 1e-10)  # TOCë¥¼ COD ëŒ€ë¦¬ë¡œ ì‚¬ìš©

# ë³€í™”ìœ¨ í”¼ì²˜
df['ìœ ëŸ‰_ë³€í™”ìœ¨'] = df['ìœ ì…ìœ ëŸ‰'].pct_change()
df['BOD_ë³€í™”ìœ¨'] = df['ìœ ì…BOD'].pct_change()
df['TN_ë³€í™”ìœ¨'] = df['ìœ ì…TN'].pct_change()

# ë¶€í•˜ëŸ‰ ë³€í™” íŒ¨í„´
df['ìœ ëŸ‰_ê°€ì†ë„'] = df['ìœ ëŸ‰_ë³€í™”ìœ¨'].diff()
```

**ê¸°ëŒ€ íš¨ê³¼**: ëª¨ë¸ í•´ì„ë ¥ í–¥ìƒ ë° ì¼ë°˜í™” ì„±ëŠ¥ ê°œì„ 

---

### 6. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**

**ë°©ë²•**: RandomizedSearchCVë¥¼ í™œìš©í•œ ì²´ê³„ì  íŠœë‹

```python
from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'estimator__max_depth': [3, 4, 5, 6],
    'estimator__learning_rate': [0.01, 0.05, 0.1],
    'estimator__n_estimators': [100, 200, 300],
    'estimator__subsample': [0.7, 0.8, 0.9],
    'estimator__colsample_bytree': [0.7, 0.8, 0.9],
    'estimator__reg_alpha': [0, 0.1, 0.5],
    'estimator__reg_lambda': [0.5, 1.0, 2.0]
}

search = RandomizedSearchCV(
    model,
    param_dist,
    n_iter=50,
    cv=TimeSeriesSplit(n_splits=3),
    scoring='r2',
    n_jobs=-1,
    random_state=42
)

search.fit(X_train, y_train)

print(f"Best params: {search.best_params_}")
print(f"Best CV score: {search.best_score_:.4f}")

# ìµœì  ëª¨ë¸ ì‚¬ìš©
best_model = search.best_estimator_
```

**ê¸°ëŒ€ íš¨ê³¼**: ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°œê²¬ìœ¼ë¡œ ì„±ëŠ¥ 5-10% í–¥ìƒ ê°€ëŠ¥

---

### 7. **ì´ìƒì¹˜ ì²˜ë¦¬**

**ë°©ë²•**: IQR ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ ë° í´ë¦¬í•‘

```python
# IQR ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ ë° í´ë¦¬í•‘
def clip_outliers(df, columns, lower_quantile=0.01, upper_quantile=0.99):
    """
    ë¶„ìœ„ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ í´ë¦¬í•‘
    """
    df_clipped = df.copy()
    for col in columns:
        lower = df[col].quantile(lower_quantile)
        upper = df[col].quantile(upper_quantile)
        df_clipped[col] = df[col].clip(lower, upper)
        print(f'{col}: [{lower:.2f}, {upper:.2f}]ë¡œ í´ë¦¬í•‘')
    return df_clipped

# ì ìš©
numeric_cols = ['ìœ ì…ìœ ëŸ‰', 'ìœ ì…BOD', 'ìœ ì…TN', 'ìœ ì…TP', 'ìœ ì…TOC', 'ìœ ì…SS']
df = clip_outliers(df, numeric_cols, lower_quantile=0.01, upper_quantile=0.99)
```

**ëŒ€ì•ˆ**: Z-score ê¸°ë°˜ ì œê±°

```python
from scipy import stats

def remove_outliers_zscore(df, columns, threshold=3):
    """
    Z-score ê¸°ë°˜ ì´ìƒì¹˜ ì œê±°
    """
    df_clean = df.copy()
    for col in columns:
        z_scores = np.abs(stats.zscore(df[col]))
        df_clean = df_clean[z_scores < threshold]
    return df_clean
```

**ê¸°ëŒ€ íš¨ê³¼**: ì •ìƒ ë²”ìœ„ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ

---

### 8. **ì‹¤ì‹œê°„ ìš´ì˜ ëŒ€ì‘**

**ë°©ë²•**: Cold Start í•´ê²° ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ

```python
# ê²°ì¸¡ì¹˜ ì „ë°©í–¥ ì±„ìš°ê¸° (ì‹¤ì‹œê°„ ì‹œë‚˜ë¦¬ì˜¤)
df_imputed = df.fillna(method='ffill', limit=3)  # ìµœëŒ€ 3ì‹œê°„ê¹Œì§€ ì´ì „ ê°’ ì‚¬ìš©

# Cold start ë¬¸ì œ í•´ê²° (ì´ˆê¸° 168ì‹œê°„)
def predict_with_fallback(model, X, y_train, min_lag_hours=168):
    """
    Lag í”¼ì²˜ ë¶€ì¡± ì‹œ í‰ê· ê°’ ê¸°ë°˜ ì˜ˆì¸¡
    """
    # Lag í”¼ì²˜ ì»¬ëŸ¼ í™•ì¸
    lag_cols = [col for col in X.columns if 'lag' in col]

    if X[lag_cols].isnull().any().any():
        # ìµœê·¼ 7ì¼ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
        print("âš ï¸ Cold start detected - using historical average")
        return y_train[-168:].mean(axis=0)
    else:
        return model.predict(X)

# ëª¨ë¸ ì¬í•™ìŠµ ì£¼ê¸° ì„¤ì •
RETRAIN_INTERVAL_DAYS = 30  # 30ì¼ë§ˆë‹¤ ì¬í•™ìŠµ
RETRAIN_THRESHOLD_MAPE = 20  # MAPE 20% ì´ˆê³¼ ì‹œ ì¡°ê¸° ì¬í•™ìŠµ

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
def monitor_model_performance(y_true, y_pred, threshold_mape=20):
    """
    ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€ íŒë‹¨
    """
    mape = safe_mape(y_true, y_pred)
    if mape > threshold_mape:
        print(f"âš ï¸ Model degradation detected: MAPE {mape:.2f}% > {threshold_mape}%")
        return True  # ì¬í•™ìŠµ í•„ìš”
    return False
```

**ê¸°ëŒ€ íš¨ê³¼**: ì•ˆì •ì ì¸ ì‹¤ì‹œê°„ ìš´ì˜ ê°€ëŠ¥

---

## ğŸ“Š ê°œì„  ìš°ì„ ìˆœìœ„

### ğŸ”´ ê¸´ê¸‰ (High Priority)
1. **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**: 1ì‹œê°„ Lag ì œê±° â†’ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê°€ëŠ¥
2. **Time Series CV ë„ì…**: ëª¨ë¸ ì•ˆì •ì„± ê²€ì¦ ê°•í™”
3. **MAPE ê³„ì‚° ìˆ˜ì •**: ì •í™•í•œ ì˜¤ì°¨ìœ¨ ì¸¡ì •

### ğŸŸ¡ ì¤‘ìš” (Medium Priority)
4. **ì •ê·œí™” ê°•í™”**: ê³¼ì í•© ì™„í™” (RÂ² 0.85~0.90 ëª©í‘œ)
5. **ì´ìƒì¹˜ ì²˜ë¦¬**: ì˜ˆì¸¡ ì•ˆì •ì„± í–¥ìƒ
6. **ì‹¤ì‹œê°„ ìš´ì˜ ëŒ€ì‘**: Cold Start ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬

### ğŸŸ¢ ê¶Œì¥ (Low Priority)
7. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: ì„±ëŠ¥ ìµœì í™”
8. **ë„ë©”ì¸ í”¼ì²˜ ì¶”ê°€**: ëª¨ë¸ í•´ì„ë ¥ ë° ì„±ëŠ¥ í–¥ìƒ

---

## ğŸ¯ ê¸°ëŒ€ íš¨ê³¼

### ì„±ëŠ¥ ëª©í‘œ
- **RÂ² Score**: 0.85 ~ 0.90 (í˜„ì¬ 0.997ì—ì„œ ì¡°ì •)
- **MAPE**: 15% ì´ë‚´ (REQ002 ëª©í‘œ ê¸°ì¤€)
- **ì‹¤ì‹œê°„ ì˜ˆì¸¡**: 1ì‹œê°„ í›„ ë¶€í•˜ëŸ‰ ì˜ˆì¸¡ ê°€ëŠ¥
- **ì•ˆì •ì„±**: ê³„ì ˆì„± ë° íŠ¸ë Œë“œ ë³€í™” ëŒ€ì‘ë ¥ í–¥ìƒ

### ìš´ì˜ ê°œì„ 
- Cold Start Problem í•´ê²° â†’ ì´ˆê¸° 7ì¼ê°„ í‰ê· ê°’ ê¸°ë°˜ ì˜ˆì¸¡
- ê²°ì¸¡ì¹˜ ëŒ€ì‘ ì „ëµ â†’ ìµœëŒ€ 3ì‹œê°„ ì „ë°©í–¥ ì±„ìš°ê¸°
- ëª¨ë¸ ì¬í•™ìŠµ ì£¼ê¸° â†’ 30ì¼ ë˜ëŠ” ì„±ëŠ¥ ì €í•˜ ì‹œ ìë™ ì¬í•™ìŠµ

---

## ğŸ“ ê²°ë¡ 

í˜„ì¬ ëª¨ë¸ì€ ë§¤ìš° ë†’ì€ í•™ìŠµ ì„±ëŠ¥(RÂ² > 0.99)ì„ ë³´ì´ì§€ë§Œ, **ê³¼ì í•©**, **ë°ì´í„° ëˆ„ìˆ˜**, **ì‹¤ì‹œê°„ ìš´ì˜ ê³ ë ¤ ë¶€ì¡±** ë“±ì˜ ë¬¸ì œë¡œ ì‹¤ì œ ë°°í¬ ì‹œ ì„±ëŠ¥ ì €í•˜ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.

ì œì•ˆëœ ê°œì„ ë°©ì•ˆì„ **ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë‹¨ê³„ì ìœ¼ë¡œ ì ìš©**í•˜ë©´, ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œë„ **ì•ˆì •ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ ì„±ëŠ¥**ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.

íŠ¹íˆ **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**ì™€ **Time Series CV ë„ì…**ì€ ì¦‰ì‹œ ì ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì‹ ë¢°ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

---

## âœ… ê°œì„ ì‚¬í•­ ì ìš© í˜„í™©

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-20

### ì ìš© ì™„ë£Œëœ ê°œì„ ì‚¬í•­

#### 1. âœ… ê³¼ì í•© í•´ê²° (ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - `max_depth`: 6 â†’ 4ë¡œ ê°ì†Œ
  - `learning_rate`: 0.1 â†’ 0.05ë¡œ ê°ì†Œ
  - `reg_alpha`: 0 â†’ 0.1 (L1 ì •ê·œí™” ì¶”ê°€)
  - `reg_lambda`: 0 â†’ 1.0 (L2 ì •ê·œí™” ê°•í™”)
- **ì½”ë“œ ìœ„ì¹˜**: [req002_model.ipynb](req002_model.ipynb) Cell #10
- **ê¸°ëŒ€ íš¨ê³¼**: ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ, Test RÂ² 0.85~0.90 ëª©í‘œ

#### 2. âœ… MAPE ê³„ì‚° ìˆ˜ì • (ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - `safe_mape()` í•¨ìˆ˜ ì¶”ê°€: epsilon=1e-10 ì‚¬ìš©í•˜ì—¬ 0 ë‚˜ëˆ„ê¸° ë°©ì§€
  - `smape()` í•¨ìˆ˜ ì¶”ê°€: Symmetric MAPE ëŒ€ì•ˆ ì œê³µ
- **ì½”ë“œ ìœ„ì¹˜**: [req002_model.ipynb](req002_model.ipynb) Cell #12
- **ê²°ê³¼**: TN ë¶€í•˜ëŸ‰ MAPE inf% ë¬¸ì œ í•´ê²°

#### 3. âœ… ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ (ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - `lag_periods`: [1, 24, 168] â†’ [24, 168]ë¡œ ë³€ê²½
  - 1ì‹œê°„ Lag í”¼ì²˜ ì œê±° (ì‹¤ì‹œê°„ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì •ë³´)
- **ì½”ë“œ ìœ„ì¹˜**: [req002_model.ipynb](req002_model.ipynb) Cell #4
- **ê¸°ëŒ€ íš¨ê³¼**: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ ê°œì„ 

#### 4. âœ… Time Series Cross-Validation ë„ì… (ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - TimeSeriesSplit(n_splits=5) êµ¬í˜„
  - 5-Fold êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ ì•ˆì •ì„± í‰ê°€
  - ê° íƒ€ê²Ÿë³„ RÂ² Mean Â± Std ì¶œë ¥
- **ì½”ë“œ ìœ„ì¹˜**: [req002_model.ipynb](req002_model.ipynb) Cell #11
- **ê¸°ëŒ€ íš¨ê³¼**: ê³„ì ˆì„± ë° íŠ¸ë Œë“œ ë³€í™”ì— ëŒ€í•œ robustness ê²€ì¦

#### 5. âœ… ë„ë©”ì¸ ê¸°ë°˜ í”¼ì²˜ ì¶”ê°€ (ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - ë¹„ìœ¨ í”¼ì²˜ 4ê°œ: BOD_TN_ratio, BOD_TP_ratio, TN_TP_ratio, COD_BOD_ratio
  - ë³€í™”ìœ¨ í”¼ì²˜ 4ê°œ: ìœ ëŸ‰/BOD/TN/TP ë³€í™”ìœ¨
  - ê°€ì†ë„ í”¼ì²˜ 1ê°œ: ìœ ëŸ‰_ê°€ì†ë„
- **ì½”ë“œ ìœ„ì¹˜**: [req002_model.ipynb](req002_model.ipynb) Cell #2-1
- **ê¸°ëŒ€ íš¨ê³¼**: ëª¨ë¸ í•´ì„ë ¥ í–¥ìƒ ë° ì¼ë°˜í™” ì„±ëŠ¥ ê°œì„ 

#### 6. âš ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ë¶€ë¶„ ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - ìˆ˜ë™ íŒŒë¼ë¯¸í„° ì¡°ì • ì™„ë£Œ (ê°œì„  1ì— í¬í•¨)
  - RandomizedSearchCV ì½”ë“œëŠ” ì£¼ì„ìœ¼ë¡œ ì œê³µ (ì‹¤í–‰ ì‹œê°„ ê³ ë ¤)
- **ì°¸ê³ **: í•„ìš”ì‹œ ë³„ë„ ì‹¤í–‰ ê¶Œì¥
- **ê¸°ëŒ€ íš¨ê³¼**: ì„±ëŠ¥ 5-10% ì¶”ê°€ í–¥ìƒ ê°€ëŠ¥

#### 7. âœ… ì´ìƒì¹˜ ì²˜ë¦¬ (ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - `clip_outliers()` í•¨ìˆ˜ êµ¬í˜„
  - 1%~99% ë¶„ìœ„ìˆ˜ ê¸°ë°˜ í´ë¦¬í•‘
  - ëª¨ë“  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì— ì ìš©
- **ì½”ë“œ ìœ„ì¹˜**: [req002_model.ipynb](req002_model.ipynb) Cell #1-1
- **ê¸°ëŒ€ íš¨ê³¼**: ê·¹ë‹¨ê°’ ì˜í–¥ ê°ì†Œ, ì˜ˆì¸¡ ì•ˆì •ì„± í–¥ìƒ

#### 8. âœ… ì‹¤ì‹œê°„ ìš´ì˜ ëŒ€ì‘ (ì™„ë£Œ)
- **ì ìš© ë‚´ìš©**:
  - `handle_missing_realtime()`: ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìµœëŒ€ 3ì‹œê°„ forward fill)
  - `predict_with_fallback()`: Cold Start ëŒ€ì‘ (ì´ˆê¸° 7ì¼ê°„ í‰ê· ê°’ ì‚¬ìš©)
  - `monitor_model_performance()`: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (MAPE 20% ì„ê³„ê°’)
- **ì½”ë“œ ìœ„ì¹˜**: [req002_model.ipynb](req002_model.ipynb) ë§ˆì§€ë§‰ ì…€
- **ìš´ì˜ ì •ì±…**:
  - ì •ê¸° ì¬í•™ìŠµ: 30ì¼ë§ˆë‹¤
  - ì¡°ê¸° ì¬í•™ìŠµ: MAPE > 20% ì‹œ
- **ê¸°ëŒ€ íš¨ê³¼**: ì•ˆì •ì ì¸ ì‹¤ì‹œê°„ ìš´ì˜ ê°€ëŠ¥

---

## ğŸ“ˆ ê°œì„  ì „í›„ ë¹„êµ

| í•­ëª© | ê°œì„  ì „ | ê°œì„  í›„ | ê°œì„  íš¨ê³¼ |
|------|---------|---------|-----------|
| Lag Features | 1h, 24h, 168h (18ê°œ) | 24h, 168h (12ê°œ) | ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê°€ëŠ¥ |
| ì •ê·œí™” | max_depth=6, lr=0.1 | max_depth=4, lr=0.05, reg | ê³¼ì í•© ë°©ì§€ |
| MAPE ê³„ì‚° | inf% ì˜¤ë¥˜ ë°œìƒ | epsilon ì¶”ê°€ë¡œ ì•ˆì •í™” | ì •í™•í•œ í‰ê°€ |
| êµì°¨ ê²€ì¦ | ë‹¨ì¼ 80/20 split | 5-Fold Time Series CV | ì•ˆì •ì„± ê²€ì¦ |
| ë„ë©”ì¸ í”¼ì²˜ | ê¸°ë³¸ í”¼ì²˜ë§Œ | +9ê°œ ë„ë©”ì¸ í”¼ì²˜ | í•´ì„ë ¥ í–¥ìƒ |
| ì´ìƒì¹˜ ì²˜ë¦¬ | ë¯¸ì²˜ë¦¬ | 1%~99% í´ë¦¬í•‘ | ì˜ˆì¸¡ ì•ˆì •ì„± |
| ì‹¤ì‹œê°„ ìš´ì˜ | ë¯¸ê³ ë ¤ | 3ê°œ ìš´ì˜ í•¨ìˆ˜ ì¶”ê°€ | ë°°í¬ ê°€ëŠ¥ |

---

## ğŸ”„ í›„ì† ì‘ì—… ê¶Œì¥ì‚¬í•­

### 1. ëª¨ë¸ ì¬í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€
- ê°œì„ ëœ ì½”ë“œë¡œ ëª¨ë¸ ì¬í•™ìŠµ ì‹¤í–‰
- Test Set ì„±ëŠ¥ í™•ì¸ (ëª©í‘œ: RÂ² 0.85~0.90, MAPE < 15%)
- 5-Fold CV ê²°ê³¼ì˜ í‘œì¤€í¸ì°¨ í™•ì¸ (ì•ˆì •ì„± ì§€í‘œ)

### 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ì„ íƒì‚¬í•­)
- RandomizedSearchCV ì‹¤í–‰ (ì‹œê°„ ì†Œìš”: ì•½ 1-2ì‹œê°„)
- ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ

### 3. ì‹¤ì‹œê°„ ìš´ì˜ í…ŒìŠ¤íŠ¸
- Cold Start ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ (ì´ˆê¸° 7ì¼ê°„)
- ê²°ì¸¡ì¹˜ ë°œìƒ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¡œì§ ê²€ì¦

### 4. ë¬¸ì„œí™”
- ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ ë³´ê³ ì„œ ì‘ì„±
- ìš´ì˜ ë§¤ë‰´ì–¼ ì‘ì„±
- API ë¬¸ì„œ ì‘ì„± (ë°°í¬ ì‹œ)

---

## ğŸ“ ì°¸ê³  íŒŒì¼

- **ëª¨ë¸ ì½”ë“œ**: [01 ìœ ì…ìˆ˜/req002_model.ipynb](req002_model.ipynb)
- **ëª¨ë¸ ê°€ì´ë“œ**: [01 ìœ ì…ìˆ˜/model_guide.md](model_guide.md) âœ¨ **NEW**
- **ë°ì´í„°ì…‹**: [dataset/20251024/ìœ ì…ìˆ˜.csv](../dataset/20251024/ìœ ì…ìˆ˜.csv)
- **ë¦¬ë·° ë¬¸ì„œ**: [01 ìœ ì…ìˆ˜/review.md](review.md)

---

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ: model_guide.md ìƒì„± ì™„ë£Œ

**ìƒì„±ì¼**: 2025-11-20

### ë¬¸ì„œ ê°œìš”
REQ002 ëª¨ë¸ì˜ **ì¢…í•© ê°€ì´ë“œ ë¬¸ì„œ**ë¡œ, ëª¨ë¸ êµ¬ì¡°, ì…ì¶œë ¥ ë°ì´í„°, ì „ì²˜ë¦¬ ê³¼ì •, ì‚¬ìš© ë°©ë²•ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

### ë¬¸ì„œ êµ¬ì„±

1. **ëª¨ë¸ ê°œìš”**
   - ëª©ì  ë° í•µì‹¬ íŠ¹ì§•
   - ì£¼ìš” ì‚¬ì–‘ (ì•Œê³ ë¦¬ì¦˜, ì˜ˆì¸¡ ëŒ€ìƒ, í”¼ì²˜ ìˆ˜ ë“±)

2. **ëª¨ë¸ ì•Œê³ ë¦¬ì¦˜ ë° êµ¬ì¡°**
   - XGBoost Multi-Output ìƒì„¸ ì„¤ëª…
   - ëª¨ë¸ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨
   - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (ìµœì í™” ì™„ë£Œ)
   - Time Series Cross-Validation ì „ëµ

3. **ì…ë ¥ ë°ì´í„° ì •ì˜** (54ê°œ í”¼ì²˜)
   - ì›ë³¸ ì…ë ¥ ë³€ìˆ˜ 6ê°œ
   - ì‹œê°„ í”¼ì²˜ 6ê°œ
   - ë„ë©”ì¸ ê¸°ë°˜ í”¼ì²˜ 9ê°œ (ë¹„ìœ¨, ë³€í™”ìœ¨, ê°€ì†ë„)
   - Lag í”¼ì²˜ 12ê°œ (24h, 168h)
   - Rolling í†µê³„ í”¼ì²˜ 16ê°œ (mean, std, max, min)

4. **ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •**
   - 11ë‹¨ê³„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„¸ ì„¤ëª…
   - ê° ë‹¨ê³„ë³„ ì½”ë“œ ì˜ˆì‹œ í¬í•¨
   - ì´ìƒì¹˜ ì²˜ë¦¬, í”¼ì²˜ ìƒì„±, ì •ê·œí™” ë°©ë²•

5. **ì¶œë ¥ ë°ì´í„° ì •ì˜** (3ê°œ ë¶€í•˜ëŸ‰)
   - BOD/TN/TP ë¶€í•˜ëŸ‰ ìƒì„¸ ì„¤ëª…
   - ì¶œë ¥ í˜•ì‹ (Python, JSON)
   - ì˜ˆì¸¡ ì‹ ë¢°ë„ ì§€í‘œ

6. **ëª¨ë¸ ì‚¬ìš© ë°©ë²•**
   - ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²•
   - ì‹¤ì‹œê°„ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤ (Cold Start, ê²°ì¸¡ì¹˜ ì²˜ë¦¬)
   - ë°°ì¹˜ ì˜ˆì¸¡
   - FastAPI ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì‹œ

7. **ì„±ëŠ¥ ì§€í‘œ**
   - ëª©í‘œ ì„±ëŠ¥ ê¸°ì¤€
   - ê°œì„  í›„ ì˜ˆìƒ ì„±ëŠ¥
   - Feature Importance Top 10
   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ì¤€

### í™œìš© ë°©ë²•

- **ê°œë°œì**: ëª¨ë¸ í†µí•© ë° API ê°œë°œ ì‹œ ì°¸ê³ 
- **ìš´ì˜ì**: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ë° ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ
- **ë¶„ì„ê°€**: ëª¨ë¸ êµ¬ì¡° ì´í•´ ë° ê°œì„  ë°©í–¥ ê²€í† 

### ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ë²„ì „ | ë³€ê²½ ë‚´ìš© |
|------|------|-----------|
| 2025-11-20 | v1.0 | ì´ˆê¸° ë²„ì „ ìƒì„± (ê°œì„ ì‚¬í•­ ë°˜ì˜ ì™„ë£Œ) |
